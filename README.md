# Machine Learning Mentorship

This is the repository that contains all the material/code required to get started with the mentorship programme. A few points of administration:

1. The length of the mentorship is around 5 weeks.

2. We assume you have some prior knowledge of programming.

3. For any help with the course, you can contact your mentor. A better option would be to open an issue on this repository, so that others can see your question, and it'll prevent any replicated effort on the part of the mentor.

4. All your code will be pushed to GitHub, so if you haven't already, create a GitHub account. Fork and clone this repository and create your respective folders (refer the sample folder with my name).

5. Create a README.md in your folder where you can keep track of your progress over the next month. The mentors will be using the README.md as a progress tracker. (Refer the sample README.md given)

Don't be afraid to ask any questions (however irrelevant you think it may be). The mentors are here to help you every step of the way.


## Prerequisites

1. Language: We'll be using Python3 throughout this course. So familiarise yourself with the language. Also learn to install packages using pip.

2. Libraries (Installation):

    a. [NumPy](https://numpy.org/): Used for matrix computations.
    
    b. [Pandas](https://pandas.pydata.org/): Used for data analysis.
    
    c. [Matplotlib](https://matplotlib.org/): Used for data visualization

4. Tools:

    a. [Jupyter Notebook](https://jupyter.org/install)
    
    b. git: You'll be using GitHub for all your code/assignment submission, so learn the basics of git: pull, push, add, commit.


## Resources

Since every one prefers a different approach to learning, we're gonna try our best to accomodate each style. Every topic has multiple levels of resources:

1. Articles/Blogs: This will give you a detailed explanation for each topic alongwith the relevant mathematics.

2. Code: If you prefer to learn by looking at the codebase, we'll link practical implementations of the topic(wherever appropriate).

3. Lectures: We'll link free online YouTube lectures (wherever appropriate).

The recommendation would be to either use Lectures or Articles to get a solid grasp of the conceptual details, and to use the Code as a reference during the assignment. Please note that we don't tolerate any plagiarism.

At the end of each week you will be given a set of tasks to complete. This could either be a report, or a coding assignment. All submissions will happen via GitHub.


## Detailed Breakdown

### WEEK 1

Basics of Python:

    a. Python Fundamentals
    
    b. Variables
    
    c. Data Types
    
    d. Operators
    
    e. Conditions and Loops
    
    f. Python Functions
    
    g. Python Data Structures
    

1. [Code](https://github.com/shivaylamba/Machine-Learning-Mentorship/blob/master/1_Intro%20to%20Python.ipynb)  
2. [Article/Tutorial](https://www.programiz.com/python-programming/tutorial)
3. [Lecture](youtube.com/watch?v=woVJ4N5nl_s)

Python for Machine Learning

   1. [Lecture](https://www.youtube.com/watch?v=KNNKJGi-F4s)

### Tasks : 


Submit your codes in Python in the Task 1 folder.

1.1 [Python If-Else](https://www.hackerrank.com/challenges/py-if-else/problem)

1.2 [Word Order](https://www.hackerrank.com/challenges/word-order/problem)

1.3 [Time Delta](https://www.hackerrank.com/challenges/python-time-delta/problem)

1.4 [Matrix Script](https://www.hackerrank.com/challenges/matrix-script/problem) (Optional)
    
---------------------------------------------------------------------------------------------------------------------------------------

### WEEK 2

NumPy

1. [Article and Code](https://github.com/shivaylamba/Machine-Learning-Mentorship/blob/master/2_Intro%20to%20numpy.ipynb)

2. [Lecture](https://www.youtube.com/watch?v=8JfDAm9y_7s)

Pandas

1. [Article and Code](https://github.com/shivaylamba/Machine-Learning-Mentorship/blob/master/3_Intro%20to%20pandas.ipynb)

2. [Lecture](https://www.youtube.com/watch?v=B42n3Pc-N2A)
 
Matplotlib

1. [Tutorial](https://pythonprogramming.net/matplotlib-python-3-basics-tutorial/)

2. [Article and Code](https://github.com/shivaylamba/Machine-Learning-Mentorship/blob/master/NumPy_Matplotlib_Pandas.ipynb)

3. [Article/Blog](https://towardsdatascience.com/matplotlib-tutorial-learn-basics-of-pythons-powerful-plotting-library-b5d1b8f67596)
    
     
### Tasks : 

Submit your code in the Task 2 folder. 

2.1 Download [this](https://s3-ap-southeast-1.amazonaws.com/he-public-data/datafiles19cdaf8.zip) dataset and perform the following tasks:

   1. Load the data (both train and test)

   2. Print the shape and display the data (using .head())

   3. Check if there are missing values in the data and replace them with "NaN"

2.2 Use [this](https://github.com/shivaylamba/Machine-Learning-Mentorship/blob/master/Dataset/stocks.csv) dataset and draw a line plot similar to that as shown [here](https://github.com/shivaylamba/Machine-Learning-Mentorship/blob/master/Dataset/line_plot.PNG)
 
----------------------------------------------------------------------------------------------------------------------------------------

### WEEK 3
  
1. [Introduction to Machine learning](https://towardsdatascience.com/machine-learning-an-introduction-23b84d51e6d0)
  
2. [Introduction to Supervised and Unsupervised Learning](https://medium.com/@saahil1292/machine-learning-101-supervised-vs-unsupervised-41312b504053)

3. [Linear regression](https://towardsdatascience.com/linear-regression-detailed-view-ea73175f6e86)
   
4. [Multivariate Regression](https://www.youtube.com/watch?v=J_LnPL3Qg70)

5. [Lecture](https://www.youtube.com/watch?v=QfOsnjxvJco&t=2s) (Recommended)


### Tasks : 

Submit your code in the Task 3 folder. 

[Air Quality Prediction](https://www.kaggle.com/chiranjeevbit/air-quality-prediction)
 
----------------------------------------------------------------------------------------------------------------------------------------

### WEEK 4
 
1. [Introduction to Logistic Regression](https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc)

2. [Lecture](https://www.youtube.com/watch?v=VCJdg7YBbAQ)

3. [Linear Regression vs Logistic Regression](https://www.youtube.com/watch?v=OCwZyYH14uw)

4. [K Nearest Neighbours](https://medium.com/datadriveninvestor/k-nearest-neighbors-knn-7b4bd0128da7)

### Tasks : 

Submit your code in the Task 4 folder. 

[Diabetes Prediction](https://www.kaggle.com/uciml/pima-indians-diabetes-database/data)

4.1 Using Logistic Regression

4.2 Using KNN
  
----------------------------------------------------------------------------------------------------------------------------------------

### WEEK 5
 
Introduction to K-Means Clustering

1. [Article/Blog](https://towardsdatascience.com/understanding-k-means-clustering-in-machine-learning-6a6e67336aa1)

2. [Article](https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-k-means-clustering/) (A bit long but quite useful)
 
Support Vector Machine

1. [Article](https://medium.com/machine-learning-101/chapter-2-svm-support-vector-machine-theory-f0812effc72)

2. [Code](analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/)

3. [Lecture](https://www.youtube.com/watch?v=TtKF996oEl8)

### Final Task : 

Submit your code in the Task 5 folder. 

**Goal** : To precisely predict individuals’ income using data collected from the 1994 U.S. Census. Your goal is to build a model that accurately predicts whether an individual makes more than $50,000.

**Dataset** : [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Census+Income)

**Dataset Description** : This dataset consists of approximately 32,000 data points, with each datapoint having 13 features. This dataset is a modified version of the dataset published in the paper “Scaling Up the Accuracy of Naive-Bayes Classifiers: a Decision-Tree Hybrid”, by Ron Kohavi.

_Features_

- `age` : Age
- `workclass` : Working Class (Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked)
- `education_level` : Level of Education (Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool)

- `education-num` : Number of educational years completed
- `marital-status` : Marital status (Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse)

- `occupation` : Work Occupation (Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces)

- `relationship` : Relationship Status (Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried)
- `race` : Race (White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black)
- `sex` : Sex (Female, Male)
- `capital-gain` : Monetary Capital Gains
- `capital-loss` : Monetary Capital Losses
- `hours-per-week` :  Average Hours Per Week Worked
- `native-country` : Native Country (United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands)

**Target Variable**

- `income` : Income Class (<=50K, >50K)

----------------------------------------------------------------------------------------------------------------------------------------

### After the programme

Machine Learning is a vast field and since the mentorship programme was limited to 4/5 weeks we covered only the basic algorithms. Below are listed some other important algorithms. I've provided a basic introduction/implementation blog for each. However you can go ahead and explore these topics further.

- Decision Trees and Random Forest

1. [Introductory Blog](https://towardsdatascience.com/decision-trees-and-random-forests-df0c3123f991)
2. [Implementation](https://jakevdp.github.io/PythonDataScienceHandbook/05.08-random-forests.html)
3. [In-depth](https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/)

- Perceptrons and Neural Network

1. [Blog](https://towardsdatascience.com/what-the-hell-is-perceptron-626217814f53)
2. [In-depth](https://www.simplilearn.com/what-is-perceptron-tutorial)

- Artificial Neural Network

1. [Blog](https://towardsdatascience.com/introduction-to-artificial-neural-networks-ann-1aea15775ef9)
2. [Implementation](https://towardsdatascience.com/applied-deep-learning-part-1-artificial-neural-networks-d7834f67a4f6)
3. [In-depth](https://www.simplilearn.com/how-to-train-artificial-neural-network-tutorial)

- Convolutional Neural Network

1. [Blog 1](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)
2. [Blog 2](https://medium.com/@RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148)

- Transfer Learning


- Recurrent Neural Network
- Generative Adversarial Networks
- Deep Convolutional GAN's (DCGANs)
